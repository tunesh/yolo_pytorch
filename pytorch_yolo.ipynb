{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_cfg(cfgfile):\n",
    "    \n",
    "    file=open(cfgfile, 'r')\n",
    "    lines=file.read().split('\\n')\n",
    "    lines=[x for x in lines if len(x)>0] #remove empty lines\n",
    "    lines=[x for x in lines if x[0] !='#'] #remove commented lines\n",
    "    lines = [x.rstrip().lstrip() for x in lines]\n",
    "    \n",
    "    block={}\n",
    "    blocks=[]\n",
    "    \n",
    "    for line in lines:\n",
    "        if line[0]=='[':\n",
    "            if len(block) != 0:\n",
    "                blocks.append(block)\n",
    "                block = {}\n",
    "            block[\"type\"] = line[1:-1].rstrip()\n",
    "            #print(block)\n",
    "            \n",
    "        else:\n",
    "            key, value=line.split('=')\n",
    "            block[key.rstrip()] = value.lstrip()\n",
    "    blocks.append(block)\n",
    "        \n",
    "    return(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#parse_cfg('C:/Users/tunes/Downloads/darknet-master/darknet-master/build/darknet/x64/yolov3_face.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_input():\n",
    "    img = cv2.imread(\"C:/Users/tunes/Downloads/test1.jpg\")\n",
    "    img = cv2.resize(img, (416,416)) \n",
    "    img_ =  img[:,:,::-1].transpose((2,0,1))\n",
    "    img_ = img_[np.newaxis,:,:,:]/255.0\n",
    "    img_ = torch.from_numpy(img_).float()\n",
    "    img_ = Variable(img_)\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Maxpoolstride1(nn.Module):\n",
    "    \n",
    "    def __inti__(self, kernel_size):\n",
    "        super(Maxpoolstride1, self).__init__()\n",
    "        self.kernel_size=kernel_size\n",
    "        self.pad=kernel_size - 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        padded_x=F.pad(x, (0,self.pad,0,self.pad), mode=\"replicate\")\n",
    "        pooled_x=nn.MaxPool2d(self.kernel_size, self.pad)(padded_x)\n",
    "        \n",
    "        return pooled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Emptylayer(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Emptylayer, self).__init__()\n",
    "       \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Detectionlayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, anchors):\n",
    "        super().__init__()\n",
    "        self.anchors=anchors\n",
    "        \n",
    "    def forward(self, x, inp_dim, classes, confidence):\n",
    "        x=x.data\n",
    "        global CUDA\n",
    "        prediction=x\n",
    "        prediction=predict_transform(prediction, inp_dim, self.anchors, classes, confidence, CUDA)\n",
    "        return prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, stride=2):\n",
    "        super().__init__()\n",
    "        self.stride=stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        stride= self.stride\n",
    "        assert(x.data.dim() == 4)\n",
    "        B=x.data.size[0]\n",
    "        C=x.data.size[1]\n",
    "        H=x.data.size[2]\n",
    "        W=x.data.size[3]\n",
    "        ws=stride\n",
    "        hs=stride\n",
    "        x=x.view(B, C, H, 1, W, 1).expand(B, C, H, stride, W, stride).contiguous().view(B, C, H*stride, W*stride)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Create_modules(blocks):\n",
    "    \n",
    "    net_info=blocks[0]\n",
    "    \n",
    "    module_list = nn.ModuleList()\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    prev_filters = 3\n",
    "    \n",
    "    output_filters = []\n",
    "    \n",
    "    for x in blocks:\n",
    "        module=nn.Sequential()\n",
    "        \n",
    "        if x['type'] == 'net':\n",
    "            continue\n",
    "            \n",
    "        if x['type'] == 'convolutional':\n",
    "            \n",
    "            activation = x['activation']\n",
    "            filters = int(x['filters'])\n",
    "            padding = int(x['pad'])\n",
    "            kernel_size = int(x['size'])\n",
    "            stride = int(x['stride'])\n",
    "            \n",
    "            try:\n",
    "                batch_normalize = x['batch_normalize']\n",
    "                bias = False\n",
    "                \n",
    "            except:\n",
    "                batch_normalize=0\n",
    "                bias=True\n",
    "            \n",
    "            if padding:\n",
    "                pad = (kernel_size - 1)//2\n",
    "            else:\n",
    "                pad = 0\n",
    "                \n",
    "            conv=nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias= bias)\n",
    "            module.add_module(\"conv_{0}\".format(index), conv)\n",
    "            \n",
    "            \n",
    "            if batch_normalize:\n",
    "                bn=nn.BatchNorm2d(filters)\n",
    "                module.add_module(\"batch_norm_{0}\".format(index), bn)\n",
    "                \n",
    "                \n",
    "            if activation=='leaky':\n",
    "                activ=nn.LeakyReLU(0.1, inplace=True)\n",
    "                module.add_module(\"leaky_{0}\".format(index), activ)\n",
    "                \n",
    "                \n",
    "        elif x['type']=='Upsample':\n",
    "            stride=int(x['stride'])\n",
    "            upsample=Upsample(stride)\n",
    "            upsample=nn.Upsample(scale_factor=2, mode='nearest')\n",
    "            module.add_module(\"upsample_{0}\".format(index), upsample)\n",
    "            \n",
    "            \n",
    "        elif x['type']=='route':\n",
    "            layers=x['layers'].split(',')\n",
    "            \n",
    "            #start of a route\n",
    "            \n",
    "            start=int(layers[0])\n",
    "            \n",
    "            #end, if exists\n",
    "            try:\n",
    "                end=int(layers[1])\n",
    "                \n",
    "            except:\n",
    "                end=0\n",
    "                \n",
    "            if start > 0:\n",
    "                start=start-index\n",
    "                \n",
    "            if end > 0:\n",
    "                end=end-index\n",
    "                \n",
    "            route=Emptylayer()\n",
    "            module.add_module(\"route_{0}\".format(index), route)\n",
    "            \n",
    "            \n",
    "            if end < 0:\n",
    "                filters=output_filters[index + start] + output_filters[index+end]\n",
    "                \n",
    "            else:\n",
    "                filters=output_filters[index + start]\n",
    "                \n",
    "            \n",
    "        elif x['type']=='shortcut':\n",
    "            from_=x['from']\n",
    "            shortcut=Emptylayer()\n",
    "            module.add_module(\"shortcut_{}\".format(index), shortcut)\n",
    "            \n",
    "            \n",
    "        elif x['type']=='maxpool':\n",
    "            \n",
    "            stride = int(x[\"stride\"])\n",
    "            size = int(x[\"size\"])\n",
    "            \n",
    "            if stride != 1:\n",
    "                \n",
    "                maxpool = nn.MaxPool2d(size, stride)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                maxpool = Maxpoolstride1(size)\n",
    "            \n",
    "            module.add_module(\"maxpool_{}\".format(index), maxpool)\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "        elif x['type']=='yolo':\n",
    "            mask=x['mask'].split(',')\n",
    "            mask=[int(x) for x in mask]\n",
    "            \n",
    "            anchors=x['anchors'].split(',')\n",
    "            anchors=[int(a) for a in anchors]\n",
    "            anchors=[(anchors[i], anchors[i+1]) for i in range(0, len(anchors), 2)]\n",
    "            anchors=[anchors[i] for i in mask]\n",
    "            \n",
    "            \n",
    "            detection=Detectionlayer(anchors)\n",
    "            module.add_module('detection_{}'.format(index), detection)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "        module_list.append(module)\n",
    "        prev_filters = filters\n",
    "        output_filters.append(filters)\n",
    "        index += 1\n",
    "        \n",
    "    \n",
    "    return (net_info, module_list)\n",
    "            \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfgfile):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.blocks = parse_cfg(cfgfile)\n",
    "        self.net_info, self.module_list = Create_modules(self.blocks)\n",
    "        self.header = torch.IntTensor([0,0,0,0])\n",
    "        self.seen = 0\n",
    "\n",
    "        \n",
    "        \n",
    "    def get_blocks(self):\n",
    "        return self.blocks\n",
    "\n",
    "    \n",
    "    def get_module_list(self):\n",
    "        return self.module_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x, CUDA = False):\n",
    "        \n",
    "        \n",
    "        detections=[]\n",
    "        \n",
    "        modules = self.blocks[1:]\n",
    "        outputs={}\n",
    "        \n",
    "        \n",
    "        write=0\n",
    "    \n",
    "        \n",
    "        for i in range(len(modules)):\n",
    "            #print(len(modules))\n",
    "            modules_type = (modules[i]['type'])\n",
    "        \n",
    "            if modules_type == 'convolution' or modules_type == 'upsample' or modules_type == 'maxpool' :\n",
    "                x=self.modules_list[i](x)\n",
    "                print(x)\n",
    "                outputs[i]=x\n",
    "                print(outputs[i])\n",
    "            elif modules_type == 'route':\n",
    "                layers = modules[i]['layers']\n",
    "                layers = [int(a) for a in layers]\n",
    "                \n",
    "                if layers[0] > 0:\n",
    "                    layers[0] = layers[0] - i\n",
    "                    \n",
    "                if len(layers) == 1:\n",
    "                    x =  outputs[i + (layers[0])]\n",
    "                    \n",
    "                else:\n",
    "                    if layers[1] > 0:\n",
    "                        layers[1] = layers[1] - i\n",
    "\n",
    "                    map1 = outputs [i + layers[0]]\n",
    "                    map2 = outputs [i + layers[1]]\n",
    "                    \n",
    "                    x = torch.cat((map1, map2), 1)\n",
    "                \n",
    "                outputs[i] = x\n",
    "                \n",
    "            elif modules_type == 'shortcut':\n",
    "                from_ = int(modules[i]['from'])\n",
    "                print(from_)\n",
    "                print(i)\n",
    "                print(outputs[i-1])\n",
    "                x = outputs[i-1] + outputs[i + from_]\n",
    "                outputs[i] = x\n",
    "                \n",
    "            \n",
    "            elif modules_type == 'yolo':\n",
    "                \n",
    "                anchors=self.module_list[i][0].anchors\n",
    "                \n",
    "                inp_dim=int(self.net_info['height'])\n",
    "                \n",
    "                num_classes=int(module[i]['classes'])\n",
    "                \n",
    "                x=x.data\n",
    "                x=predict_transform(x, inp_dim, anchors, num_classes, CUDA)\n",
    "                \n",
    "                if type(x) == int:\n",
    "                    continue\n",
    "                    \n",
    "                if not write:\n",
    "                    detections = x\n",
    "                    write = 1 \n",
    "                    \n",
    "                else:\n",
    "                    detections = torch.cat((detection, x), 1)\n",
    "                    \n",
    "                outputs[i] = outputs[i-1]\n",
    "                \n",
    "                \n",
    "                \n",
    "        try:\n",
    "            return detections\n",
    "        \n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "                 \n",
    "    def load_weights(self, weightfile):\n",
    "        \n",
    "        fp = open(weightfile, 'rb')\n",
    "        \n",
    "        \n",
    "        header = np.fromfile(fp, dtype = np.int32, count = 5)\n",
    "        self.header = torch.from_numpy(header)\n",
    "        self.seen = self.header[3]\n",
    "            \n",
    "        \n",
    "        weights = np.fromfile(fp, dtype = np.float32)\n",
    "        \n",
    "        ptr = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(self.module_list)):\n",
    "            \n",
    "            module_type = self.blocks[i+1]['type']\n",
    "            \n",
    "            if module_type == 'convolutional':\n",
    "                model = self.module_list[i]\n",
    "                \n",
    "                try:\n",
    "                    batch_normalize = int(self.blocks[i+1]['batch_normalize'])\n",
    "                    \n",
    "                except:\n",
    "                    batch_normalize = 0\n",
    "                    \n",
    "                \n",
    "                conv = model[0]\n",
    "                \n",
    "                if batch_normalize:\n",
    "                    \n",
    "                    bn = model[1]\n",
    "                    \n",
    "                    num_bn_biases = bn.bias.numel()\n",
    "                    \n",
    "                    bn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "                    \n",
    "                    bn_weights = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "                    \n",
    "                    bn_running_mean = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "                    \n",
    "                    bn_running_var = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "                    \n",
    "                    bn_biases = bn_biases.view_as(bn.bias.data)\n",
    "                    bn_weights = bn_weights.view_as(bn.weight.data)\n",
    "                    bn_running_mean = bn_running_mean.view_as(bn.running_mean)\n",
    "                    bn_running_var = bn_running_var.view_as(bn.running_var)\n",
    "                    \n",
    "                    \n",
    "                    bn.bias.data.copy_(bn_biases)\n",
    "                    bn.weight.data.copy_(bn_weights)\n",
    "                    bn.running_mean.copy_(bn_running_mean)\n",
    "                    bn.running_var.copy_(bn_running_var)\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    num_biases = conv.bias.numel()\n",
    "                    \n",
    "                    conv_biases = torch.from_numpy(weights[ptr:ptr  + num_biases])\n",
    "                    ptr += num_biases\n",
    "                    \n",
    "                    conv_biases = conv_biases.view_as(conv.bias.data)\n",
    "                    \n",
    "                    conv.bias.data.copy_(conv_biases)\n",
    "                    \n",
    "                \n",
    "                num_weights = conv.weight.numel()\n",
    "                \n",
    "                conv_weights = torch.from_numpy(weights[ptr:ptr + num_weights])\n",
    "                ptr += num_weights\n",
    "                #print(conv_weights.shape)\n",
    "                conv_weights = conv_weights.view_as(conv.weight.data)\n",
    "                \n",
    "                conv.weight.data.copy_(conv_weights)\n",
    "                \n",
    "                \n",
    "                    \n",
    "    def save_weights(self, savedfile, cutoff = 0):\n",
    "        \n",
    "        if cutoff <= 0:\n",
    "            cutoff = len(self.blocks) - 1\n",
    "            \n",
    "        fp = open(savedfile, 'wb')\n",
    "        \n",
    "        self.header[3] = self.seen\n",
    "        header = self.header\n",
    "        \n",
    "        header = header.numpy()\n",
    "        header.tofile(fp)\n",
    "        \n",
    "        \n",
    "        for i in range(len(self.module_list)):\n",
    "            module_type = self.block[i+1]['type']\n",
    "            \n",
    "            \n",
    "            if module_type == 'convolutional':\n",
    "                model = self.module_list[i]\n",
    "                \n",
    "                try:\n",
    "                    batch_normalize = int(self.block[i+1]['batch_normalize'])\n",
    "                    \n",
    "                except:\n",
    "                    batch_normalize = 0\n",
    "                \n",
    "                conv = model[0]\n",
    "                \n",
    "                if batch_normalize:\n",
    "                    bn = model[1]\n",
    "                    \n",
    "                    \n",
    "                    cpu(bn.bias.data).numpy().tofile(fp)\n",
    "                    cpu(bn.weights.data).numpy().tofile(fp)\n",
    "                    cpu(bn.running_mean).numpy().tofile(fp)\n",
    "                    cpu(bn.running_var).numpy().tofile(fp)\n",
    "                    \n",
    "                else:\n",
    "                    cpu(conv.bias.data).numpy().tofile(fp)\n",
    "                    \n",
    "                \n",
    "                cpu(conv.weights.data).numpy().tofile(fp)\n",
    "                \n",
    "                \n",
    "            \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Darknet('C:/Users/tunes/Downloads/darknet-master/darknet-master/build/darknet/x64/yolov3_face.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.load_weights('C:/Users/tunes/Downloads/darknet-master/darknet-master/build/darknet/x64/yolov3.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = get_test_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-b468145848a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Softwares\\anacond33\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-159-d9ab623fdc52>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, CUDA)\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "s,d = a(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Darknet('C:/Users/tunes/Downloads/darknet-master/darknet-master/build/darknet/x64/yolov3_face.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v.load_weights('C:/Users/tunes/Downloads/darknet-master/darknet-master/build/darknet/x64/yolov3.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = get_test_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-4aea6bdd18bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Softwares\\anacond33\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-164-d5cfe6a16042>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, CUDA)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;31m#Output the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCUDA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict_transform' is not defined"
     ]
    }
   ],
   "source": [
    "s,d = v(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
